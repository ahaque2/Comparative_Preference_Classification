{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/labeled_data/CPC_labeled_proc_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, '/home/ahaque2/code/utils')\n",
    "from WordEmbedding import WordEmbedding\n",
    "we = WordEmbedding(1)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def get_masked_embedding(texts):\n",
    "    \n",
    "    sent_emb = []\n",
    "    for txt in texts:\n",
    "        emb_mapp = we.get_word_embeddings([txt.strip()])\n",
    "        #print(emb_mapp.tolist()[0])\n",
    "        #sys.exit()\n",
    "        sent_emb.append(emb_mapp.tolist()[0])\n",
    "        \n",
    "    return np.array(sent_emb)\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def get_bert_sent_emb(sentences):\n",
    "\n",
    "    # Load model from HuggingFace Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "    model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling. In this case, max pooling.\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    return sentence_embeddings        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'cpc'   # 'cpc'\n",
    "if task == 'csi':\n",
    "    y_true = df['comparison'].astype(int).tolist()\n",
    "else:\n",
    "    y_true = df['preferred'].tolist()\n",
    "    \n",
    "#y_true = df['preferred'].tolist()\n",
    "input_text = df['proc_sent'].tolist()\n",
    "X = np.array(input_text)\n",
    "y = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data():\n",
    "\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    sss = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state=0)\n",
    "    #print(sss.get_n_splits(input_text, y_true))\n",
    "    X = np.array(input_text)\n",
    "    y = np.array(y_true)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    \n",
    "    np.save('final_data/train_index.npy', train_index)\n",
    "    np.save('final_data/test_index.npy', test_index)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def get_data(task):\n",
    "    \n",
    "    if task == 'csi':\n",
    "        train_index = np.load('final_data/comp/train_index.npy')\n",
    "        test_index = np.load('final_data/comp/test_index.npy')\n",
    "        val_index = np.load('final_data/comp/val_index.npy')\n",
    "    else:\n",
    "        train_index = np.load('final_data/pref/train_index.npy')\n",
    "        test_index = np.load('final_data/pref/test_index.npy')\n",
    "        val_index = np.load('final_data/pref/val_index.npy')\n",
    "        \n",
    "    train_index = np.concatenate((train_index, val_index))\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    return  X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = get_data('cpc')\n",
    "#X_train, X_test, y_train, y_test = sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent_emb = get_bert_sent_emb(X_train.tolist())\n",
    "test_sent_emb = get_bert_sent_emb(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sent_emb = get_embedding_features(X_train)\n",
    "# test_sent_emb = get_embedding_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sent_emb = np.array(sent_emb)\n",
    "train_sent_emb.shape, test_sent_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#clf = AdaBoostClassifier(n_estimators=100)\n",
    "#clf = RandomForestClassifier(n_estimators=100)\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "#clf = GaussianNB()\n",
    "#clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "#clf = MLPClassifier(random_state=1, max_iter=300)\n",
    "clf = NearestCentroid()\n",
    "\n",
    "clf.fit(train_sent_emb, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_sent_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKlearn Multi-Class multioutput classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def multiclass_multioutput_classifier(train_sent_emb, test_sent_emb, df):\n",
    "    \n",
    "    X = train_sent_emb\n",
    "    y = np.array(pd.concat((df['comparison'], df['preferred']), axis = 1))\n",
    "    y_train = y[train_index]\n",
    "    clf = MultiOutputClassifier(KNeighborsClassifier()).fit(X, y_train)\n",
    "\n",
    "    y_pred = clf.predict(test_sent_emb)\n",
    "    y_pred_comp, y_pred_pref = y_pred[:,0], y_pred[:,1]\n",
    "    y_true = y[test_index]\n",
    "    y_true_comp, y_true_pref = y_true[:,0], y_true[:,1]\n",
    "    \n",
    "    return y_pred_comp, y_pred_pref\n",
    "\n",
    "task = 'cpc'\n",
    "if task == 'csi':\n",
    "    train_index = np.load('final_data/comp/train_index.npy')\n",
    "    test_index = np.load('final_data/comp/test_index.npy')\n",
    "    val_index = np.load('final_data/comp/val_index.npy')\n",
    "else:\n",
    "    train_index = np.load('final_data/pref/train_index.npy')\n",
    "    test_index = np.load('final_data/pref/test_index.npy')\n",
    "    val_index = np.load('final_data/pref/val_index.npy')\n",
    "        \n",
    "train_index = np.concatenate((train_index, val_index))\n",
    "\n",
    "y_pred_comp, y_pred_pref = multiclass_multioutput_classifier(train_sent_emb, test_sent_emb, df)\n",
    "\n",
    "y_test = df['comparison'][test_index]\n",
    "y_pred = y_pred_comp\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "y_test = df['preferred'][test_index]\n",
    "y_pred = y_pred_pref\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
