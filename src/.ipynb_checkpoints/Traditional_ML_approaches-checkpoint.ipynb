{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 2283\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "\n",
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def get_masked_embedding(texts):\n",
    "    \n",
    "    sent_emb = []\n",
    "    for txt in texts:\n",
    "        emb_mapp = we.get_word_embeddings([txt.strip()])\n",
    "        sent_emb.append(emb_mapp.tolist()[0])\n",
    "        \n",
    "    return np.array(sent_emb)\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def get_bert_sent_emb(sentences):\n",
    "\n",
    "    # Load model from HuggingFace Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "    model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling. In this case, max pooling.\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    return sentence_embeddings        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \n",
    "    train_df = pd.read_csv('../data/train.csv')\n",
    "    test_df = pd.read_csv('../data//test.csv')\n",
    "    val_df = pd.read_csv('../data/val.csv')\n",
    "        \n",
    "    train_df = pd.concat((train_df, val_df), axis = 0)\n",
    "    \n",
    "    return  train_df, test_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'preferred'\n",
    "train_df, test_df, val_df = get_data()\n",
    "X_train = train_df['proc_sent']\n",
    "y_train = train_df[task]\n",
    "\n",
    "X_test = test_df['proc_sent']\n",
    "y_test = test_df[task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7112,), (7112,), (1778,), (1778,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "train_sent_emb = get_bert_sent_emb(X_train.tolist())\n",
    "test_sent_emb = get_bert_sent_emb(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7112, 768]), torch.Size([1778, 768]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sent_emb.shape, test_sent_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(gamma='auto'))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Uncomment the algorithm you want to use\n",
    "\n",
    "#clf = AdaBoostClassifier(n_estimators=100)\n",
    "#clf = RandomForestClassifier(n_estimators=100)\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "#clf = GaussianNB()\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "#clf = MLPClassifier(random_state=1, max_iter=300)\n",
    "#clf = NearestCentroid()\n",
    "\n",
    "clf.fit(train_sent_emb, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixie overall performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N     0.6263    0.3684    0.4639       323\n",
      "           O     0.7104    0.7963    0.7509       653\n",
      "           T     0.7699    0.8217    0.7949       802\n",
      "\n",
      "    accuracy                         0.7300      1778\n",
      "   macro avg     0.7022    0.6621    0.6699      1778\n",
      "weighted avg     0.7219    0.7300    0.7186      1778\n",
      "\n",
      "[[119 108  96]\n",
      " [ 32 520 101]\n",
      " [ 39 104 659]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(test_sent_emb)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implcit comparison class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N     0.6000    0.3375    0.4320       160\n",
      "           O     0.7679    0.8562    0.8096       452\n",
      "           T     0.7756    0.8112    0.7930       392\n",
      "\n",
      "    accuracy                         0.7560      1004\n",
      "   macro avg     0.7145    0.6683    0.6782      1004\n",
      "weighted avg     0.7441    0.7560    0.7430      1004\n",
      "\n",
      "[[ 54  59  47]\n",
      " [ 20 387  45]\n",
      " [ 16  58 318]]\n"
     ]
    }
   ],
   "source": [
    "X_test_imp = test_df[test_df['comparison'] == 1]['proc_sent']\n",
    "y_test_imp = test_df[test_df['comparison'] == 1][task]\n",
    "\n",
    "test_sent_emb_imp = get_bert_sent_emb(X_test_imp.tolist())\n",
    "\n",
    "y_pred_imp = clf.predict(test_sent_emb_imp)\n",
    "\n",
    "print(classification_report(y_test_imp, y_pred_imp, digits=4))\n",
    "print(confusion_matrix(y_test_imp, y_pred_imp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit comparison class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N     0.6500    0.3988    0.4943       163\n",
      "           O     0.5833    0.6617    0.6200       201\n",
      "           T     0.7646    0.8317    0.7967       410\n",
      "\n",
      "    accuracy                         0.6964       774\n",
      "   macro avg     0.6660    0.6307    0.6370       774\n",
      "weighted avg     0.6934    0.6964    0.6872       774\n",
      "\n",
      "[[ 65  49  49]\n",
      " [ 12 133  56]\n",
      " [ 23  46 341]]\n"
     ]
    }
   ],
   "source": [
    "X_test_exp = test_df[test_df['comparison'] == 2]['proc_sent']\n",
    "y_test_exp = test_df[test_df['comparison'] == 2][task]\n",
    "\n",
    "test_sent_emb_exp = get_bert_sent_emb(X_test_exp.tolist())\n",
    "\n",
    "y_pred_exp = clf.predict(test_sent_emb_exp)\n",
    "\n",
    "print(classification_report(y_test_exp, y_pred_exp, digits=4))\n",
    "print(confusion_matrix(y_test_exp, y_pred_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
